{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAKSK8ED0H9WYfjqN+mgKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bimawahy/chatbot/blob/main/ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset sederhana\n",
        "data = [\n",
        "    (\"buy cheap viagra\", \"spam\"),\n",
        "    (\"win money lottery\", \"spam\"),\n",
        "    (\"hello how are you\", \"not_spam\"),\n",
        "    (\"cheap loan offer\", \"spam\"),\n",
        "    (\"how about meeting\", \"not_spam\")\n",
        "]\n",
        "\n",
        "# Preprocessing: Tokenisasi dan pemisahan data\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# Memisahkan data berdasarkan kelas\n",
        "def separate_by_class(data):\n",
        "    spam = []\n",
        "    not_spam = []\n",
        "    for text, label in data:\n",
        "        if label == \"spam\":\n",
        "            spam.append(text)\n",
        "        else:\n",
        "            not_spam.append(text)\n",
        "    return spam, not_spam\n",
        "\n",
        "spam, not_spam = separate_by_class(data)\n",
        "\n",
        "# Menghitung probabilitas prior\n",
        "total_emails = len(data)\n",
        "p_spam = len(spam) / total_emails\n",
        "p_not_spam = len(not_spam) / total_emails\n",
        "\n",
        "# Menghitung frekuensi kata dalam setiap kelas\n",
        "def word_frequencies(texts):\n",
        "    frequencies = {}\n",
        "    for text in texts:\n",
        "        words = tokenize(text)\n",
        "        for word in words:\n",
        "            frequencies[word] = frequencies.get(word, 0) + 1\n",
        "    return frequencies\n",
        "\n",
        "spam_word_counts = word_frequencies(spam)\n",
        "not_spam_word_counts = word_frequencies(not_spam)\n",
        "\n",
        "# Menghitung jumlah total kata dalam setiap kelas\n",
        "spam_total_words = sum(spam_word_counts.values())\n",
        "not_spam_total_words = sum(not_spam_word_counts.values())\n",
        "\n",
        "# Semua kata unik di dataset\n",
        "all_words = set(tokenize(\" \".join([text for text, label in data])))\n",
        "\n",
        "# Menghitung probabilitas kata menggunakan Laplace Smoothing\n",
        "def word_probabilities(word_counts, total_words, vocab_size):\n",
        "    probabilities = {}\n",
        "    for word in all_words:\n",
        "        probabilities[word] = (word_counts.get(word, 0) + 1) / (total_words + vocab_size)\n",
        "    return probabilities\n",
        "\n",
        "vocab_size = len(all_words)\n",
        "spam_word_probs = word_probabilities(spam_word_counts, spam_total_words, vocab_size)\n",
        "not_spam_word_probs = word_probabilities(not_spam_word_counts, not_spam_total_words, vocab_size)\n",
        "\n",
        "# Fungsi prediksi\n",
        "def predict(text):\n",
        "    words = tokenize(text)\n",
        "    spam_score = p_spam\n",
        "    not_spam_score = p_not_spam\n",
        "\n",
        "    for word in words:\n",
        "        spam_score *= spam_word_probs.get(word, 1 / (spam_total_words + vocab_size))\n",
        "        not_spam_score *= not_spam_word_probs.get(word, 1 / (not_spam_total_words + vocab_size))\n",
        "\n",
        "    return \"spam\" if spam_score > not_spam_score else \"not_spam\"\n",
        "\n",
        "# Menguji model\n",
        "test_email = \"cheap money offer\"\n",
        "print(f\"Email: '{test_email}' -> Prediction: {predict(test_email)}\")\n"
      ],
      "metadata": {
        "id": "CwskSiO3HLh_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}